{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from collections.abc import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import load_model\n",
    "\n",
    "from monai.networks.blocks.segresnet_block import ResBlock, get_conv_layer, get_upsample_layer\n",
    "from monai.networks.layers.factories import Dropout\n",
    "from monai.networks.layers.utils import get_act_layer, get_norm_layer\n",
    "from monai.utils import UpsampleMode\n",
    "from typing import Union, Tuple, List, Dict, Optional\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int = 3,\n",
    "        init_filters: int = 8,\n",
    "        in_channels: int = 1,\n",
    "        out_channels: int = 2,\n",
    "        dropout_prob: Union[float, None] = None,\n",
    "        act: Union[Tuple, str] = (\"RELU\", {\"inplace\": True}),\n",
    "        norm: Union[Tuple, str] = (\"GROUP\", {\"num_groups\": 8}),\n",
    "        norm_name: str = \"\",\n",
    "        num_groups: int = 8,\n",
    "        use_conv_final: bool = True,\n",
    "        blocks_down: Tuple[int, ...] = (1, 2, 2, 4),\n",
    "        blocks_up: Tuple[int, ...] = (1, 1, 1),\n",
    "        upsample_mode: Union[UpsampleMode, str] = UpsampleMode.NONTRAINABLE,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if spatial_dims not in (2, 3):\n",
    "            raise ValueError(\"`spatial_dims` can only be 2 or 3.\")\n",
    "\n",
    "        self.spatial_dims = spatial_dims\n",
    "        self.init_filters = init_filters\n",
    "        self.in_channels = in_channels\n",
    "        self.blocks_down = blocks_down\n",
    "        self.blocks_up = blocks_up\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.act = act  # input options\n",
    "        self.act_mod = get_act_layer(act)\n",
    "        if norm_name:\n",
    "            if norm_name.lower() != \"group\":\n",
    "                raise ValueError(f\"Deprecating option 'norm_name={norm_name}', please use 'norm' instead.\")\n",
    "            norm = (\"group\", {\"num_groups\": num_groups})\n",
    "        self.norm = norm\n",
    "        self.upsample_mode = UpsampleMode(upsample_mode)\n",
    "        self.use_conv_final = use_conv_final\n",
    "        self.convInit = get_conv_layer(spatial_dims, in_channels, init_filters)\n",
    "        self.down_layers = self._make_down_layers()\n",
    "        self.up_layers, self.up_samples = self._make_up_layers()\n",
    "        self.conv_final = self._make_final_conv(out_channels)\n",
    "\n",
    "        if dropout_prob is not None:\n",
    "            self.dropout = Dropout[Dropout.DROPOUT, spatial_dims](dropout_prob)\n",
    "\n",
    "    def _make_down_layers(self):\n",
    "        down_layers = nn.ModuleList()\n",
    "        blocks_down, spatial_dims, filters, norm = (self.blocks_down, self.spatial_dims, self.init_filters, self.norm)\n",
    "        for i, item in enumerate(blocks_down):\n",
    "            layer_in_channels = filters * 2**i\n",
    "            pre_conv = (\n",
    "                get_conv_layer(spatial_dims, layer_in_channels // 2, layer_in_channels, stride=2)\n",
    "                if i > 0\n",
    "                else nn.Identity()\n",
    "            )\n",
    "            down_layer = nn.Sequential(\n",
    "                pre_conv, *[ResBlock(spatial_dims, layer_in_channels, norm=norm, act=self.act) for _ in range(item)]\n",
    "            )\n",
    "            down_layers.append(down_layer)\n",
    "        return down_layers\n",
    "\n",
    "    def _make_up_layers(self):\n",
    "        up_layers, up_samples = nn.ModuleList(), nn.ModuleList()\n",
    "        upsample_mode, blocks_up, spatial_dims, filters, norm = (\n",
    "            self.upsample_mode,\n",
    "            self.blocks_up,\n",
    "            self.spatial_dims,\n",
    "            self.init_filters,\n",
    "            self.norm,\n",
    "        )\n",
    "        n_up = len(blocks_up)\n",
    "        for i in range(n_up):\n",
    "            sample_in_channels = filters * 2 ** (n_up - i)\n",
    "            up_layers.append(\n",
    "                nn.Sequential(\n",
    "                    *[\n",
    "                        ResBlock(spatial_dims, sample_in_channels // 2, norm=norm, act=self.act)\n",
    "                        for _ in range(blocks_up[i])\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            up_samples.append(\n",
    "                nn.Sequential(\n",
    "                    *[\n",
    "                        get_conv_layer(spatial_dims, sample_in_channels, sample_in_channels // 2, kernel_size=1),\n",
    "                        get_upsample_layer(spatial_dims, sample_in_channels // 2, upsample_mode=upsample_mode),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        return up_layers, up_samples\n",
    "\n",
    "    def _make_final_conv(self, out_channels: int):\n",
    "        return nn.Sequential(\n",
    "            get_norm_layer(name=self.norm, spatial_dims=self.spatial_dims, channels=self.init_filters),\n",
    "            self.act_mod,\n",
    "            get_conv_layer(self.spatial_dims, self.init_filters, out_channels, kernel_size=1, bias=True),\n",
    "        )\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "        x = self.convInit(x)\n",
    "        if self.dropout_prob is not None:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        down_x = []\n",
    "\n",
    "        for down in self.down_layers:\n",
    "            x = down(x)\n",
    "            down_x.append(x)\n",
    "\n",
    "        return x, down_x\n",
    "\n",
    "    def decode(self, x: torch.Tensor, down_x: List[torch.Tensor]) -> torch.Tensor:\n",
    "        for i, (up, upl) in enumerate(zip(self.up_samples, self.up_layers)):\n",
    "            x = up(x) + down_x[i + 1]\n",
    "            x = upl(x)\n",
    "\n",
    "        if self.use_conv_final:\n",
    "            x = self.conv_final(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x, down_x = self.encode(x)\n",
    "        down_x.reverse()\n",
    "\n",
    "        x = self.decode(x, down_x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/2023-11-08_19-19-58/train_summary.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m run_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2023-11-08_19-19-58\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m run_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mruns/\u001b[39m\u001b[39m{\u001b[39;00mrun_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m train_summary \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39;49m(run_path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtrain_summary.json\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      7\u001b[0m model_name \u001b[39m=\u001b[39m train_summary[\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mMODEL\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m IMAGE_SIZE \u001b[39m=\u001b[39m train_summary[\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mIMAGE_SIZE\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/CV701_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/2023-11-08_19-19-58/train_summary.json'"
     ]
    }
   ],
   "source": [
    "run_name = \"2023-11-08_19-19-58\"\n",
    "\n",
    "run_path = f\"runs/{run_name}/\"\n",
    "\n",
    "train_summary = json.load(open(run_path + \"train_summary.json\"))\n",
    "\n",
    "model_name = train_summary[\"config\"][\"MODEL\"]\n",
    "IMAGE_SIZE = train_summary[\"config\"][\"IMAGE_SIZE\"]\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "model = SegResNet(in_channels=1, out_channels=2, spatial_dims=2)\n",
    "model = load_model(model, run_path + \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "example = torch.rand(1, 1, 224, 224)\n",
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module_optimized = optimize_for_mobile(traced_script_module)\n",
    "traced_script_module_optimized._save_for_lite_interpreter(\"model.ptl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV701_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
